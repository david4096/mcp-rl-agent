# Default configuration for MCP RL Agent

# MCP Servers Configuration
mcp_servers:
  - id: "mock_basic"
    name: "Mock Basic Tools Server"
    transport: "stdio"
    command: ["python", "-m", "mcp_rl_agent.mcp.mock_server", "stdio"]
    timeout: 30.0
    retry_attempts: 3
    retry_delay: 1.0

# LLM Configuration
llm:
  provider: "mock"
  model_name: "mock_model"
  max_tokens: 1024
  temperature: 0.7
  responses:
    - "I understand. Let me help you with that using the available tools."
    - "I'll work on this task right away."
    - "Let me use the appropriate tool to accomplish this."
    - "I've completed the requested action successfully."
    - "That's an interesting request. I'll see what I can do."
  delay: 0.1

# Reinforcement Learning Configuration
rl:
  learning_rate: 0.0003
  gamma: 0.99
  gae_lambda: 0.95
  clip_range: 0.2
  n_steps: 128
  batch_size: 32
  n_epochs: 4
  hidden_size: 256
  n_layers: 2
  activation: "relu"
  ent_coef: 0.01
  vf_coef: 0.5
  max_grad_norm: 0.5
  save_freq: 100
  eval_freq: 50

# Environment Configuration
environment:
  max_episode_length: 50
  reward_scale: 1.0
  context_window: 10
  embedding_dim: 512
  success_reward: 1.0
  failure_penalty: -0.1
  step_penalty: -0.01
  repetition_penalty: -0.1
  max_actions_per_turn: 5
  action_timeout: 30.0

# Operator Interface Configuration
operator:
  type: "mock"
  responses:
    - "Hello! Can you help me calculate 2 + 3?"
    - "That's helpful. Can you echo 'Hello World'?"
    - "Great! What's the weather like in San Francisco?"
    - "Perfect. Can you write 'Test content' to a file called test.txt?"
    - "Thank you! That's all I need."
  feedback_scores: [0.8, 0.9, 0.7, 0.85, 1.0]
  delay: 0.5
  timeout: 60.0

# Logging Configuration
logging:
  level: "INFO"
  structured: true
  json_logs: false

# Global Settings
seed: 42
debug: false